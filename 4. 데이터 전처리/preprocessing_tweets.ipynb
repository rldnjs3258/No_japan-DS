{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>retweets</th>\n",
       "      <th>likes</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Esthersumi</td>\n",
       "      <td>2019-08-17 23:36:36</td>\n",
       "      <td>126</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>한국인과 결혼해서 광고도 찍고 방송에도 나오다 홀연히 사라진 일본인.. 그 후 혐한...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>chunnha</td>\n",
       "      <td>2019-08-17 22:52:19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>일본군 둥닝요새의 ‘위안부 참상’  중국 헤이룽장성의 관동군 주둔지에서 고초 겪은 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>hyeong_chun</td>\n",
       "      <td>2019-08-17 22:45:06</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>이형춘(Hyeong Chun Lee): 노인과 권위의 나라 일본(Japan  cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>woori153</td>\n",
       "      <td>2019-08-17 22:41:22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>일본 패망 할때까지 쭈우욱 가야죠. #노 재팬</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>LoveMoon012</td>\n",
       "      <td>2019-08-17 22:11:04</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>문재인 대통령의 방향성이 옳다는 것을 다시 한 번 확인하게 되네. No 아베로 그칠...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      username            timestamp  retweets  likes  is_retweet  \\\n",
       "0   Esthersumi  2019-08-17 23:36:36       126     42           0   \n",
       "1      chunnha  2019-08-17 22:52:19         1      0           0   \n",
       "2  hyeong_chun  2019-08-17 22:45:06         0      1           0   \n",
       "3     woori153  2019-08-17 22:41:22         1      2           0   \n",
       "4  LoveMoon012  2019-08-17 22:11:04        17     12           0   \n",
       "\n",
       "                                                text  \n",
       "0  한국인과 결혼해서 광고도 찍고 방송에도 나오다 홀연히 사라진 일본인.. 그 후 혐한...  \n",
       "1  일본군 둥닝요새의 ‘위안부 참상’  중국 헤이룽장성의 관동군 주둔지에서 고초 겪은 ...  \n",
       "2  이형춘(Hyeong Chun Lee): 노인과 권위의 나라 일본(Japan  cou...  \n",
       "3                          일본 패망 할때까지 쭈우욱 가야죠. #노 재팬  \n",
       "4  문재인 대통령의 방향성이 옳다는 것을 다시 한 번 확인하게 되네. No 아베로 그칠...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 일본, 불매, 일제, no japan, 일본여행, 노재팬\n",
    "general = pd.read_csv('2019-09-21_tweets.csv')\n",
    "# 아사히, 유니클로, 대마도, 규슈, 후쿠오카, 데상트, DHC, 캐논,  도요타\n",
    "com_area = pd.read_csv('2019-09-21_tweets_company.csv')\n",
    "tweet_data = pd.concat([general, com_area])\n",
    "tweet_data = tweet_data.drop(['Unnamed: 0'], axis=1)\n",
    "tweet_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검색된 내용 중 중복된 내용의 트윗을 제거한다.\n",
    "\n",
    "- username과 text가 완전히 일치한다고 무조건 중복된 내용이라 볼 수 없다고 가정한다. 왜냐하면 같은 사람이 다른 날 같은 내용을 올리는 것은 관심도가 유지되고 있다는 것으로 가정하기 때문이다.\n",
    "- username, timestamp, text가 완전히 일치한다면 같은 트윗이다. 날짜 이외의 시간은 의미없으므로 지워준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복 제거 전: 128194\n",
      "중복 제거 후: 125724\n"
     ]
    }
   ],
   "source": [
    "def modify_time(time):\n",
    "    return time[:10]\n",
    "\n",
    "# 날짜만 남김\n",
    "tweet_data['timestamp'] = tweet_data['timestamp'].apply(modify_time)\n",
    "\n",
    "print('중복 제거 전: {}'.format(len(tweet_data)))\n",
    "tweet_data = tweet_data.drop_duplicates(['username', 'timestamp', 'text'], keep='last').reset_index(drop=True)\n",
    "print('중복 제거 후: {}'.format(len(tweet_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동일인물이 같은 날에 쓴 트윗들은 하나로 합쳐 한 사람의 의견이 여러 번 반영되지 않도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = tweet_data[tweet_data.duplicated(['username']).apply(lambda x: not x)].reset_index(drop=True)\n",
    "dup_username_tweets = tweet_data[tweet_data.duplicated(['username'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15595 / 15595"
     ]
    }
   ],
   "source": [
    "usernames = list(set(dup_username_tweets['username'].values))\n",
    "for i, username in enumerate(usernames):\n",
    "    # 진행개수 출력\n",
    "    print('\\r{} / {}'.format(i, 15595), end='')\n",
    "    \n",
    "    rows = dup_username_tweets[dup_username_tweets['username']==username]\n",
    "    duplicated = rows.duplicated(['timestamp'])\n",
    "    if duplicated.sum() == 0:\n",
    "        continue\n",
    "        \n",
    "    processed_data = processed_data.append(rows[duplicated.apply(lambda x: not x)], ignore_index=True)\n",
    "    rows = rows[duplicated]\n",
    "    timestamps = list(set(rows['timestamp'].values))\n",
    "    for timestamp in timestamps:\n",
    "        likes = rows['likes'].sum()\n",
    "        retweets = rows['retweets'].sum()\n",
    "        new_text = ''\n",
    "        for text in rows['text']:\n",
    "            new_text = new_text + ' ' + text\n",
    "            \n",
    "        processed_data = processed_data.append({'username': username, 'timestamp':timestamp, 'retweets':retweets,\n",
    "                               'likes':likes, 'is_retweet':0, 'text':new_text}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리 전 : 125724\n",
      "처리 후 : 88917\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>retweets</th>\n",
       "      <th>likes</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>88910</td>\n",
       "      <td>Schalom1004</td>\n",
       "      <td>2019-07-22</td>\n",
       "      <td>294</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "      <td>쪽바리의 근성.  유니클로가 코리아 블랙프라이데이 세일 기간에 1만2900원짜리 T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88911</td>\n",
       "      <td>Schalom1004</td>\n",
       "      <td>2019-07-10</td>\n",
       "      <td>5237</td>\n",
       "      <td>3435</td>\n",
       "      <td>0</td>\n",
       "      <td>일본도 한국제품 불매운동 하고 있음  일본제품 불매운동 소비제품 품목.  맥주&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88912</td>\n",
       "      <td>Schalom1004</td>\n",
       "      <td>2019-07-03</td>\n",
       "      <td>5237</td>\n",
       "      <td>3435</td>\n",
       "      <td>0</td>\n",
       "      <td>일본도 한국제품 불매운동 하고 있음  일본제품 불매운동 소비제품 품목.  맥주&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88913</td>\n",
       "      <td>Schalom1004</td>\n",
       "      <td>2019-07-12</td>\n",
       "      <td>5237</td>\n",
       "      <td>3435</td>\n",
       "      <td>0</td>\n",
       "      <td>일본도 한국제품 불매운동 하고 있음  일본제품 불매운동 소비제품 품목.  맥주&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88914</td>\n",
       "      <td>Schalom1004</td>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>5237</td>\n",
       "      <td>3435</td>\n",
       "      <td>0</td>\n",
       "      <td>일본도 한국제품 불매운동 하고 있음  일본제품 불매운동 소비제품 품목.  맥주&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88915</td>\n",
       "      <td>Schalom1004</td>\n",
       "      <td>2019-07-04</td>\n",
       "      <td>5237</td>\n",
       "      <td>3435</td>\n",
       "      <td>0</td>\n",
       "      <td>일본도 한국제품 불매운동 하고 있음  일본제품 불매운동 소비제품 품목.  맥주&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88916</td>\n",
       "      <td>Schalom1004</td>\n",
       "      <td>2019-07-25</td>\n",
       "      <td>5237</td>\n",
       "      <td>3435</td>\n",
       "      <td>0</td>\n",
       "      <td>일본도 한국제품 불매운동 하고 있음  일본제품 불매운동 소비제품 품목.  맥주&gt; ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username   timestamp  retweets  likes  is_retweet  \\\n",
       "88910  Schalom1004  2019-07-22       294    167           0   \n",
       "88911  Schalom1004  2019-07-10      5237   3435           0   \n",
       "88912  Schalom1004  2019-07-03      5237   3435           0   \n",
       "88913  Schalom1004  2019-07-12      5237   3435           0   \n",
       "88914  Schalom1004  2019-08-10      5237   3435           0   \n",
       "88915  Schalom1004  2019-07-04      5237   3435           0   \n",
       "88916  Schalom1004  2019-07-25      5237   3435           0   \n",
       "\n",
       "                                                    text  \n",
       "88910  쪽바리의 근성.  유니클로가 코리아 블랙프라이데이 세일 기간에 1만2900원짜리 T...  \n",
       "88911   일본도 한국제품 불매운동 하고 있음  일본제품 불매운동 소비제품 품목.  맥주> ...  \n",
       "88912   일본도 한국제품 불매운동 하고 있음  일본제품 불매운동 소비제품 품목.  맥주> ...  \n",
       "88913   일본도 한국제품 불매운동 하고 있음  일본제품 불매운동 소비제품 품목.  맥주> ...  \n",
       "88914   일본도 한국제품 불매운동 하고 있음  일본제품 불매운동 소비제품 품목.  맥주> ...  \n",
       "88915   일본도 한국제품 불매운동 하고 있음  일본제품 불매운동 소비제품 품목.  맥주> ...  \n",
       "88916   일본도 한국제품 불매운동 하고 있음  일본제품 불매운동 소비제품 품목.  맥주> ...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('처리 전 : {}'.format(len(tweet_data)))\n",
    "print('처리 후 : {}'.format(len(processed_data)))\n",
    "processed_data.tail(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전처리 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data.to_csv('processed_tweetData.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분석 --- 진행 중..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['세상은',\n",
       " '넓고',\n",
       " '모지리들은',\n",
       " '많다',\n",
       " '.',\n",
       " '모지리',\n",
       " '질량보존의',\n",
       " '법칙도',\n",
       " '아니고',\n",
       " '...',\n",
       " '방사능이',\n",
       " '위험한데도',\n",
       " '그저',\n",
       " '좋다고',\n",
       " '놀러',\n",
       " '간다',\n",
       " '.',\n",
       " '일본에',\n",
       " '여행가고',\n",
       " '물건',\n",
       " '사주면',\n",
       " '그게',\n",
       " '다',\n",
       " '전쟁준비하는',\n",
       " '군자금',\n",
       " '이',\n",
       " '되는',\n",
       " '것도',\n",
       " '모르고',\n",
       " '그저',\n",
       " '좋',\n",
       " '단다',\n",
       " '.',\n",
       " '방사능에',\n",
       " '피폭되면',\n",
       " '자자손손',\n",
       " '어찌될지',\n",
       " '모르는데',\n",
       " '그래도',\n",
       " 'NO',\n",
       " 'JAPAN',\n",
       " '안할래',\n",
       " '?']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from soynlp.tokenizer import RegexTokenizer\n",
    "from konlpy.tag import Twitter\n",
    "\n",
    "tokenizer = RegexTokenizer()\n",
    "tokened_content = tokenizer.tokenize(sample_tweet['text'])\n",
    "print(len(tokened_content))\n",
    "tokened_content   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 일본 불매에 대해 긍정적인가 부정적인가\n",
    "2. 일본에 대해 긍정적인가 부정적인가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 1.205 Gbse memory 1.347 Gb\n",
      "all cohesion probabilities was computed. # words = 6342\n",
      "all branching entropies was computed # words = 171433\n",
      "all accessor variety was computed # words = 171433\n"
     ]
    }
   ],
   "source": [
    "from soynlp.word import WordExtractor\n",
    "\n",
    "word_extractor = WordExtractor(min_frequency=100, min_cohesion_forward=0.05)\n",
    "word_extractor.train(com_area['text'])\n",
    "words = word_extractor.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어   (빈도수, cohesion, branching entropy)\n",
      "\n",
      "..     (2660, 0.918, 5.059)\n",
      "유니클로     (28266, 0.947, 4.891)\n",
      "...     (1783, 0.784, 5.055)\n",
      "캐논     (12317, 0.934, 4.870)\n",
      "!!     (353, 0.927, 4.825)\n",
      "후쿠오카     (21461, 0.954, 4.762)\n",
      "진짜     (4177, 0.659, 5.097)\n",
      "아사히     (21035, 0.685, 4.836)\n",
      "....     (596, 0.590, 4.851)\n",
      "??     (321, 0.783, 4.542)\n",
      "까지     (215, 0.358, 5.219)\n",
      "ㅠㅠ     (2350, 0.854, 4.323)\n",
      "!!!     (177, 0.682, 4.548)\n",
      "DHC     (7229, 0.947, 4.211)\n",
      "후쿠오카에서     (1330, 0.557, 4.706)\n",
      "너무     (4098, 0.780, 4.340)\n",
      "데상트     (1363, 0.726, 4.373)\n",
      "근데     (2207, 0.629, 4.498)\n",
      "때문에     (637, 0.559, 4.569)\n",
      ".....     (251, 0.542, 4.548)\n",
      "일본     (18512, 0.668, 4.326)\n",
      "맥주     (3668, 0.947, 3.932)\n",
      "했는데     (658, 0.458, 4.579)\n",
      "???     (199, 0.697, 4.129)\n",
      "ㅜㅜ     (485, 0.702, 4.098)\n",
      "불매운동     (5294, 0.754, 4.021)\n",
      "ㅋㅋ     (6102, 0.881, 3.860)\n",
      "브랜드     (1709, 0.821, 3.907)\n",
      "합니다.     (491, 0.684, 4.087)\n",
      "갑자기     (503, 0.752, 3.990)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def word_score(score):\n",
    "    return (score.cohesion_forward * math.exp(score.right_branching_entropy))\n",
    "\n",
    "print('단어   (빈도수, cohesion, branching entropy)\\n')\n",
    "for word, score in sorted(words.items(), key=lambda x:word_score(x[1]), reverse=True)[:30]:\n",
    "    print('%s     (%d, %.3f, %.3f)' % (\n",
    "            word, \n",
    "            score.leftside_frequency, \n",
    "            score.cohesion_forward,\n",
    "            score.right_branching_entropy\n",
    "            )\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
